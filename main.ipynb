{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "353ae1d0",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "# AIML 425 - Assignment 3\n",
    "## Problem 2: Variational Auto Encoders and Auto Encoders\n",
    "\n",
    "This notebook is provided for ease of use for marking. However it sohuld be noted that the development was conducted with the notebook as script percent format. The assignment repository can be found at [my gitea instance](https://gitea.james-server.duckdns.org/james/AIML425_assignment_3)  \n",
    "\n",
    "Most of the interesting good stuff is in the `src/` directory this file just runs the experiments and call the implementations.\n",
    "\n",
    "## Global imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2159fc",
   "metadata": {
    "lines_to_next_cell": 0,
    "title": "Start up"
   },
   "outputs": [],
   "source": [
    "from jax import random\n",
    "from jax import numpy as jnp\n",
    "from importlib import reload\n",
    "from functools import partial\n",
    "\n",
    "from src import model, train, data, inspect\n",
    "\n",
    "# This is the main key used for all random operations.\n",
    "key = random.key(42)\n",
    "\n",
    "reload(model)\n",
    "reload(train)\n",
    "reload(data)\n",
    "reload(inspect)\n",
    "\n",
    "################################################################################\n",
    "################################################################################\n",
    "\n",
    "# ------------ Data generation -----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fb2a08",
   "metadata": {},
   "source": [
    "###############################################################################\n",
    "# Generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9867d54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(data)\n",
    "reload(inspect)\n",
    "\n",
    "dim = (28, 28)\n",
    "size_bounds = (7, 14)\n",
    "\n",
    "database = data.generate_database(100, random.key(4), dim=dim, size_bounds=size_bounds)\n",
    "\n",
    "inspect.vis_grid(database[:25])\n",
    "\n",
    "all_possible_images, parameters = data.generate_all_possible_images(dim=dim, size_bounds=size_bounds)\n",
    "\n",
    "num_possible = len(all_possible_images)\n",
    "\n",
    "print(f\"Number of possible images: {num_possible}, with shape {all_possible_images.shape}\")\n",
    "\n",
    "\n",
    "\n",
    "# Randomly sample 6,000 images from possible images to be training\n",
    "key, subkey = random.split(key)\n",
    "train_indices = random.choice(subkey, num_possible, shape=((9 * num_possible)//10,), replace=False)\n",
    "key, subkey = random.split(subkey)\n",
    "mask = jnp.ones(num_possible, dtype=bool).at[train_indices].set(False)\n",
    "valid_indices = jnp.where(mask)[0]\n",
    "\n",
    "print(f\"Training on {len(train_indices)} images, validating on {len(valid_indices)} images\")\n",
    "\n",
    "train_batches = partial(data.create_batches, all_possible_images[train_indices])\n",
    "\n",
    "valid_batches = partial(data.create_batches, all_possible_images[valid_indices])\n",
    "\n",
    "# train_batches = partial(data.create_batches, data.generate_database(10000, key, dim=dim, size_bounds=size_bounds))\n",
    "\n",
    "# valid_batches = partial(data.create_batches, data.generate_database(2000, key, dim=dim, size_bounds=size_bounds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e18461d",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "\n",
    "################################################################################\n",
    "################################################################################\n",
    "\n",
    "# ------------ VARIATIONAL AUTO ENCODER SECTION -----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0db940f",
   "metadata": {},
   "source": [
    "###############################################################################\n",
    "# Train a VAE model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856b9b19",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "reload(train)\n",
    "reload(data)\n",
    "reload(model)\n",
    "reload(inspect)\n",
    "\n",
    "vae_trained_model, vae_history = train.do_complete_experiment(\n",
    "    key,\n",
    "    train_batches,\n",
    "    valid_batches,\n",
    "    model_class=model.VAE,\n",
    "    loss_fn=partial(\n",
    "        train.vae_loss_fn,\n",
    "        kl_beta=0.65\n",
    "    ),\n",
    "    learning_rate=0.001,\n",
    "    minibatch_size=512,\n",
    "    latent_dim=32,\n",
    "    encoder_arch=[1000, 1000, 1000, 500 ],\n",
    "    decoder_arch=[500, 1000, 1000, 1000],\n",
    "    num_epochs=1000,\n",
    "    eval_every=20,\n",
    "    dropout=0.1, \n",
    ")\n",
    "\n",
    "inspect.plot_training_history(vae_history)\n",
    "inspect.final_performance_information(vae_trained_model, all_possible_images, key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952c7ade",
   "metadata": {},
   "source": [
    "## Understand the performance of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbc0a7b",
   "metadata": {
    "title": "Understand latent space distribution"
   },
   "outputs": [],
   "source": [
    "\n",
    "reload(inspect)\n",
    "inspect.visualize_latent_space(vae_trained_model, next(train_batches(key=key, minibatch_size=1000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872d2cdf",
   "metadata": {
    "lines_to_next_cell": 2,
    "title": "Inspecting the output"
   },
   "outputs": [],
   "source": [
    "reload(inspect)\n",
    "\n",
    "\n",
    "batch = next(train_batches(key=key, minibatch_size=10))\n",
    "inspect.visualize_reconstruction(vae_trained_model, batch, rng_key=key, num_images=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d140763e",
   "metadata": {},
   "source": [
    "Understanding the performance of the generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2c030f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(inspect)\n",
    "generated_imgs = inspect.sample_and_generate(vae_trained_model, num_samples=9, rng_key=key)\n",
    "\n",
    "inspect.vis_grid(generated_imgs, name='vae-generated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e908eb91",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "reload(inspect)\n",
    "# This is simply to help intuitively select the threshold for what counts as an attempt\n",
    "inspect.visualize_neighbors(vae_trained_model, 15, all_possible_images, k=8, max_dist=50, rng_key=key, distance='euclidean')\n",
    "\n",
    "\n",
    "################################################################################\n",
    "################################################################################\n",
    "\n",
    "# ------------ AUTO ENCODER SECTION -----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604ce73a",
   "metadata": {},
   "source": [
    "# Train an AutoEncoder model\n",
    "###############################################################################\n",
    "###############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c4b576",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(train)\n",
    "reload(data)\n",
    "reload(model)\n",
    "reload(inspect)\n",
    "\n",
    "ae_trained_model, ae_history = train.do_complete_experiment(\n",
    "    key,\n",
    "    train_batches,\n",
    "    valid_batches,\n",
    "    model_class=model.AutoEncoder,\n",
    "    model_kwargs={\n",
    "        \"latent_noise_scale\": 0.1\n",
    "    },\n",
    "    loss_fn=partial(\n",
    "        train.ae_loss_fn,\n",
    "        regularization_weight=0.1,\n",
    "        mmd_sigma=(0.5, 1, 3, 5) # Use basic mean and variance control\n",
    "    ),\n",
    "    learning_rate=0.001,\n",
    "    minibatch_size=64,\n",
    "    latent_dim=10,\n",
    "    encoder_arch=[1000, 1000, 500],\n",
    "    decoder_arch=[500, 1000, 1000],\n",
    "    num_epochs=500,\n",
    "    eval_every=10,\n",
    "    dropout=0.1,\n",
    ")\n",
    "\n",
    "inspect.plot_training_history(ae_history)\n",
    "inspect.final_performance_information(ae_trained_model, all_possible_images, key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095ed1dc",
   "metadata": {},
   "source": [
    "## Understand the performance of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c781b2",
   "metadata": {
    "lines_to_next_cell": 2,
    "title": "Visualize latent space"
   },
   "outputs": [],
   "source": [
    "\n",
    "reload(inspect)\n",
    "inspect.visualize_latent_space(ae_trained_model, next(train_batches(key=key, minibatch_size=1000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85115c9f",
   "metadata": {
    "lines_to_next_cell": 2,
    "title": "Inspecting the output"
   },
   "outputs": [],
   "source": [
    "reload(inspect)\n",
    "\n",
    "\n",
    "batch = next(train_batches(key=key, minibatch_size=10))\n",
    "inspect.visualize_reconstruction(ae_trained_model, batch, rng_key=key, num_images=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2470abd8",
   "metadata": {},
   "source": [
    "Understanding the performance of the generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089debed",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(inspect)\n",
    "generated_imgs = inspect.sample_and_generate(ae_trained_model, num_samples=9, rng_key=key)\n",
    "\n",
    "\n",
    "inspect.vis_grid(generated_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da917662",
   "metadata": {
    "lines_to_next_cell": 2,
    "title": "Estimate information rate"
   },
   "outputs": [],
   "source": [
    "\n",
    "reload(inspect)\n",
    "\n",
    "info_rate = inspect.estimate_information_rate(ae_trained_model, all_possible_images)\n",
    "\n",
    "print(f\"Estimated information rate: {info_rate:.4f} bits\")\n",
    "print(f\"Which allows for {2**info_rate:.1f} distinct numbers to be represented, which is {2**info_rate/len(all_possible_images):.1f} numbers per possible image\")\n",
    "real_count = 2 ** jnp.ceil(jnp.log2(info_rate)).astype(int)\n",
    "print(f\"Next power of two: {real_count} bits or {real_count // 8} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c3e241",
   "metadata": {
    "title": "Explanation of what the latent space means for AE"
   },
   "outputs": [],
   "source": [
    "# ## Explaining the AE latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99c7f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation to known features\n",
    "reload(inspect)\n",
    "\n",
    "correlation = inspect.latent_space_correlation(ae_trained_model, all_possible_images, parameters)\n",
    "\n",
    "inspect.visualize_latent_correlation(correlation, feature_names=[\"shape\", \"size\", \"x\", \"y\"], name=\"ae-latent-corelation\")\n",
    "\n",
    "inspect.visualize_latent_by_category(ae_trained_model, all_possible_images, parameters[:, 0], name=\"ae-latent-by-shape\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7db68fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Varying latent dimensions and seeing the effect\n",
    "\n",
    "reload(inspect)\n",
    "\n",
    "inspect.zero_out_latent_and_reconstruct(\n",
    "    ae_trained_model,\n",
    "    all_possible_images[jnp.floor(jnp.linspace(0, len(all_possible_images)-1, 5)).astype(int)],\n",
    "    name=\"ae-zero-out\")\n",
    "\n",
    "inspect.latent_space_traversal_and_reconstruct(\n",
    "    ae_trained_model,\n",
    "    all_possible_images[jnp.floor(jnp.linspace(0, len(all_possible_images)-1, 3)).astype(int)],\n",
    "    traversal_range=(-3, 3),\n",
    "    steps=7,\n",
    "    name=\"ae-traversal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc16a1a",
   "metadata": {},
   "source": [
    "\n",
    "# Comparing the two models\n",
    "\n",
    "To compare these two models I will simply run the final performane information function and put that in a table. It hives a good understanding of reocnsutrction error and some understanding of generative performaance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4404df",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "reload(inspect)\n",
    "\n",
    "inspect.create_comparison_table(vae_trained_model, ae_trained_model, all_possible_images, key, \"ae-vs-vae\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "title,-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
